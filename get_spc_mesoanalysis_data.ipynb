{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2PZSCUuJusG/+PdKxZozt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tjturnage/get-spc-meso-data/blob/main/get_spc_mesoanalysis_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Get SPC mesoanalysis data</h1>\n",
        "\n",
        "<h4>Choose from sectors below</h4>\n",
        "<table>\n",
        "<tr>\n",
        "<td>11</td><td>Northwest</td>\n",
        "<td>12</td><td>Southwest</td>\n",
        "<td>13</td><td>Northern Plains</td>\n",
        "<tr>\n",
        "<td>14</td><td>Central Plains</td>\n",
        "<td>15</td><td>Southern Plains</td>\n",
        "<td>16</td><td>Northeast</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>17</td><td>East Central</td>\n",
        "<td>18</td><td>Southeast</td>\n",
        "<td>19</td><td>National</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>20</td><td>Midwest</td>\n",
        "<td>21</td><td>Great Lakes</td>\n",
        "<td></td><td></td>\n",
        "</tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "0BuxtBkl6pCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown <br><font color=\"blue\"><h2>Enter the start time (in UTC) for the data</h2></font>\n",
        "start_date = \"2024-07-05\" # @param {type:\"date\"}\n",
        "start_hour = \"19\" # @param [\"00\",\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17,\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\"]\n",
        "\n",
        "start_datetime_str = f\"{start_date}_{start_hour}\"\n",
        "\n",
        "# @markdown <br><font color=\"blue\"><h2>Desired number of hours</h2></font>\n",
        "hours_duration = \"4\" # @param [1,2,3,4,5,6]\n",
        "\n",
        "# @markdown <br><font color=\"blue\"><h2>Sector ID (see table above)</h2></font>\n",
        "sector = \"21\" # @param [\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\"]\n",
        "\n",
        "# @markdown <br><font color=\"blue\"><h2>Choose graphics types</h2></font>\n",
        "surface = True # @param {type:\"boolean\"}\n",
        "upper_air = True # @param {type:\"boolean\"}\n",
        "thermodynamics = True # @param {type:\"boolean\"}\n",
        "wind_shear = True # @param {type:\"boolean\"}\n",
        "composite_indices = True # @param {type:\"boolean\"}\n",
        "multi_parameter_fields = True # @param {type:\"boolean\"}\n",
        "beta = True # @param {type:\"boolean\"}\n",
        "heavy_rain = False # @param {type:\"boolean\"}\n",
        "winter_weather = False # @param {type:\"boolean\"}\n",
        "fire_weather = False # @param {type:\"boolean\"}\n",
        "classic = False # @param {type:\"boolean\"}\n",
        "\n",
        "groups = [surface, upper_air, thermodynamics, wind_shear, composite_indices, multi_parameter_fields, beta, heavy_rain, winter_weather, fire_weather, classic]\n",
        "\n",
        "sfc = [\n",
        "['pmsl', 'Pressure and Wind'], ['bigsfc', 'Surface Plot'], ['ttd', 'Temp/Wind/Dwpt'],\n",
        "['thet', 'MSL Press/Theta-e/Wind'], ['mcon', 'Moisture Convergence'], ['thea', 'Theta-E Advection'],\n",
        "['mxth', 'Mixing Ratio / Theta'], ['icon', 'Inst Contraction Rate'], ['trap', 'Fluid Trapping'],\n",
        "['vtm', 'Velocity Tensor Mag'], ['dvvr', 'Sfc Div and Vort'],\n",
        "['def', 'Deformation / Axis of Dilitation'],['pchg', '2hr Press Change'],\n",
        "['temp_chg', '3hr Temp Change'], ['dwpt_chg', '3hr Dewpoint Change'],\n",
        "['mixr_chg', '3hr 100mb MixR Change'], ['thte_chg', '3hr Thetae Change']]\n",
        "\n",
        "ua =[['925mb', '925mb Analysis'], ['850mb2', '850mb Analysis'],\n",
        "['850mb', '850mb Analysis v2'], ['700mb', '700mb Analysis'], ['500mb', '500mb Analysis'],\n",
        "['300mb', '300mb Analysis'], ['dlcp', 'Deep Moist Conv'], ['tadv_925', '925mb Temp Adv'],\n",
        "['tadv', '850mb Temp Adv'], ['7tad', '700mb Temp Adv'], ['sfnt', 'Surface FGEN'],\n",
        "['9fnt', '925mb FGEN'], ['8fnt', '850mb FGEN'], ['7fnt', '700mb FGEN'], ['epvl', '850 fgen & EPV'],\n",
        "['epvm', '700 fgen & EPV'], ['98ft', '925-850mb FGEN'], ['857f', '850-700mb FGEN'],\n",
        "['75ft', '700-500mb FGEN'], ['vadv', '700-400mb Diff PVA'], ['padv', '400-250mb Pot Vort Adv'],\n",
        "['ddiv', '850-250mb Diff Div'], ['ageo', '300mb Jet Circ'], ['500mb_chg', '12hr H5 chg'],\n",
        "['trap_500', 'Fluid Trapping (H500)'], ['trap_250', 'Fluid Trapping (H250)']]\n",
        "\n",
        "thermo = [['sbcp', 'SBCAPE'], ['mlcp', 'MLCAPE'], ['mucp', 'MUCAPE'],\n",
        "['eltm', 'EL Temp/MUCAPE/MUCIN'], ['ncap', 'CAPE - Normalized'], ['dcape', 'CAPE - Downdraft'],\n",
        "['muli', 'Sfc Based LI'], ['laps', 'Mid-Level Lapse Rates'], ['lllr', 'Low-Level Lapse Rates'],\n",
        "['maxlr', 'Max 2-6 km AGL Lapse Rate'], ['lclh', 'LCL hght'], ['lfch', 'LFC hght'],\n",
        "['lfrh', 'LCL-LFC RH'], ['sbcp_chg', '3-hour SBCAPE Change'], ['sbcn_chg', '3-hour SBCIN Change'],\n",
        "['mlcp_chg', '3-hour MLCAPE Change'], ['mucp_chg', '3-hour MUCAPE Change'],\n",
        "['lllr_chg', '3-hour Low LR Change'], ['laps_chg', '6-hour Mid LR Change'],\n",
        "['skewt', 'Skew-T Maps']]\n",
        "\n",
        "wshr = [['eshr', 'Bulk Shear - Effective'], ['shr6', 'Bulk Shear - Sfc-6km'],\n",
        "['shr8', 'Bulk Shear - Sfc-8km'], ['shr3', 'Bulk Shear - Sfc-3km'],\n",
        "['shr1', 'Bulk Shear - Sfc-1km'],['brns', 'BRN Shear'], ['effh', 'SR Helicity - Effective'],\n",
        "['srh3', 'SR Helicity - Sfc-3km'], ['srh1', 'SR Helicity - Sfc-1km'],\n",
        "['srh5', 'SR Helicity - Sfc-500m'], ['llsr', 'SR Wind - Sfc-2km'], ['mlsr', 'SR Wind - 4-6km'],\n",
        "['ulsr', 'SR Wind - 9-11km'], ['alsr', 'SR Wind - Anvil Level'], ['mnwd', '850-300mb Mean Wind'],\n",
        "['xover', '850 and 500mb Winds'], ['srh3_chg', '3hr Sfc-3km SR Helicity Change'],\n",
        "['shr1_chg', '3hr Sfc-1km Bulk Shear Change'], ['shr6_chg', '3hr Sfc-6km Bulk Shear Change'],\n",
        "['hodo', 'Hodograph Map']]\n",
        "\n",
        "comp = [['scp', 'Supercell Composite'], ['stor', 'Sig Tor (fixed)'],\n",
        "['stpc', 'Sig Tor (eff)'], ['stpc5', 'Sig Tor (0-500m SRH)'], ['sigt1', 'Cond Prob SigTor 1'],\n",
        "['sigt2', 'Cond Prob SigTor 2'], ['nstp', 'Non-Supercell Tor'], ['vtp3', 'Violent Tor Parm'],\n",
        "['sigh', 'Significant Hail'], ['sars1', 'SARS Hail Size'], ['sars2', 'SARS Hail %age'],\n",
        "['lghl', 'Large Hail Parm'], ['dcp', 'Derecho Comp'], ['cbsig', 'Craven/Brooks SigSvr'],\n",
        "['brn', 'Bulk Ri Number'], ['mcsm', 'MCS Maint'], ['mbcp', 'Microburst Composite'],\n",
        "['desp', 'Enh Stretch Pot'], ['ehi1', 'EHI - Sfc-1km'], ['ehi3', 'EHI - Sfc-3km'],\n",
        "['vgp3', 'VGP - Sfc-3km'], ['crit', 'Critical Angle']]\n",
        "\n",
        "multi = [['mlcp_eshr', 'MLCAPE / Eff Shear'],['cpsh', 'MUCAPE / Eff Shear'],\n",
        "['comp', 'MU LI / H8 & H5 Wind'], ['lcls', 'LCL Hgt / 0-1 SRH'],\n",
        "['lr3c', '0-3km Lapse Rate/MLCAPE'], ['3cape_shr3', '0-3km Bulk Shear/MLCAPE'],\n",
        "['3cvr', 'Sfc Vort / 0-3km MLCAPE'], ['tdlr', 'Sfc Dwpt / H7-H5 LapseR'],\n",
        "['qlcs1', '0-3km ThetaE diff/Shear Vec & MUCAPE'],\n",
        "['qlcs2', '', '0-3km ThetaE diff/Shear Vec & MLCAPE']]\n",
        "\n",
        "heavy = [['pwtr', 'PWAT'], ['tran_925', '925 Moist Trans'], ['tran', '850 Moist Trans'],\n",
        "['tran_925-850', '925-850 Mtrans'],['prop', 'Propagation Vec'], ['peff', 'Pcpn Potential'],\n",
        "['mixr', '100mb Mean Mixing Ratio']]\n",
        "\n",
        "winter = [['ptyp', 'Precipitation Type'], ['epvl', '800-750mb EPVg'],\n",
        "['epvm', '650-500mb EPVg'],['les1', 'Lake Effect Snow 1'],['les2', 'Lake Effect Snow 2'],\n",
        "['snsq', 'Snow Squall Parameter'],\n",
        "['dend', 'Dendritic Growth Layer Depth'], ['dendrh', 'Dendritic Growth Layer RH']]\n",
        "\n",
        "fire = [ ['sfir', 'Sfc RH / T / Wind'], ['fosb', 'Fosberg Index'],\n",
        "['lhan', 'Low Haines Index'],['mhan', 'Mid Haines Index'],['hhan', 'High Haines Index'],\n",
        "['lasi', 'Lower Atmos Severity Index']]\n",
        "\n",
        "oldies = [['ttot', 'Total Totals'], ['show', 'Showalter Index'], ['kidx', 'K Index']]\n",
        "\n",
        "newies = [['sherbe', 'SHERBE'], ['moshe', 'Modified SHERBE'], ['cwasp', 'CWASP'],\n",
        "['tehi', 'Tornadic 0-1 km EHI'], ['tts', 'Tornadic Tilting and Stretching parameter (TTS)'],\n",
        "['ptstpe', 'Conditional probability of EF0+ tornadoes'],\n",
        "['pstpe', 'Conditional probability of EF2+ tornadoes'], ['pvstpe', 'Conditional probability of EF4+ tornadoes']]\n",
        "\n",
        "group_list = []\n",
        "lists = [sfc, ua, thermo, wshr, comp, multi, newies,\n",
        "         heavy, winter, fire, oldies]\n",
        "\n",
        "for g,l in zip(groups,lists):\n",
        "    if g:\n",
        "      group_list.append(l)\n"
      ],
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "id": "H-uzawWfHxVf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from datetime import datetime,timedelta\n",
        "import urllib.request\n",
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "\n",
        "BASEDIR = \"/content/graphics\"\n",
        "if not os.path.exists(BASEDIR):\n",
        "    os.mkdir(BASEDIR)\n",
        "\n",
        "viewer_url = \"https://raw.githubusercontent.com/tjturnage/Meteorological-Case-Study-Tools/main/spc_meso_graphics_viewer.html\"\n",
        "\n",
        "class GetMesoImages:\n",
        "    \"\"\"\n",
        "    start_date_hour\n",
        "            string: Date and Hour to start grabbing images -- yyyymmdd_hh\n",
        "    total_hours\n",
        "            int: number of hours from startingDateHour to grab images\n",
        "    sector\n",
        "            2 digit string (not integer) representing SPC meso sector to download\n",
        "                11:NW       12:SW           13:N Plns\n",
        "                14:C Plns   15:S Plns       16:NE\n",
        "                17:EC       18:SE           19:National\n",
        "                20:MW       21:Great Lakes\n",
        "    parm_groups\n",
        "            list of lists of strings. options are:\n",
        "                [surface, upper_air, thermodynamics, wind_shear, composite_indices,\n",
        "                multi_parameter_fields, heavy_rain, winter_weather, fire_weather, classic, beta]\n",
        "    location_bool\n",
        "            True: if obtaining images from a case requested of SPC\n",
        "                    -https://www.spc.noaa.gov/exper/mesoanalysis/archive/\n",
        "            False: if searching to see if images for a date already exist in their main directory\n",
        "                    -https://www.spc.noaa.gov/exper/mesoanalysis/\n",
        "    \"\"\"\n",
        "    def __init__(self,start_date_hour,total_hours,sector,parm_groups,location_bool):\n",
        "        \"\"\"\n",
        "        initialize instance\n",
        "        \"\"\"\n",
        "        self.start_date_hour = start_date_hour\n",
        "        self.total_hours = int(total_hours) - 1\n",
        "        self.sector_name = 's' + sector\n",
        "        self.parm_groups = parm_groups\n",
        "        self.location_bool = location_bool\n",
        "        self.url_pre = self.get_url_pre()\n",
        "        self.date_hour_list = self.make_date_hour_list()\n",
        "        self.graphics_list = self.make_graphics_list()\n",
        "        self.clean_data()\n",
        "        self.download_and_store_images()\n",
        "        self.zip_files()\n",
        "\n",
        "    def clean_data(self) -> None:\n",
        "        \"\"\"\n",
        "        very hard-coded remove for now\n",
        "        \"\"\"\n",
        "        if os.path.exists(BASEDIR):\n",
        "            os.system(f'rm -rf /content/graphics')\n",
        "\n",
        "    def zip_files(self) -> None:\n",
        "        \"\"\"\n",
        "        creates a zip file of all graphics\n",
        "        \"\"\"\n",
        "        shutil.make_archive(f'meso_graphics', 'zip', '/content/graphics')\n",
        "\n",
        "\n",
        "    def make_date_hour_list(self) -> list:\n",
        "        \"\"\"\n",
        "        use datetime to create list of strings representing date and hour\n",
        "        \"\"\"\n",
        "        date_hour_list = []\n",
        "        starting_datehour = datetime.strptime(self.start_date_hour,\"%Y-%m-%d_%H\")\n",
        "        ending_datehour = starting_datehour + timedelta(hours=self.total_hours)\n",
        "        while starting_datehour <= ending_datehour:\n",
        "            dt_str = datetime.strftime(starting_datehour,'%y%m%d%H')\n",
        "            date_hour_list.append(dt_str)\n",
        "            starting_datehour = starting_datehour + timedelta(hours=1)\n",
        "        return date_hour_list\n",
        "\n",
        "    def get_url_pre(self) -> str:\n",
        "        \"\"\"\n",
        "        set the url based on selection\n",
        "        \"\"\"\n",
        "        if self.location_bool:\n",
        "            return 'https://www.spc.noaa.gov/exper/mesoanalysis/archive/'\n",
        "        return 'https://www.spc.noaa.gov/exper/mesoanalysis/'\n",
        "\n",
        "    def make_graphics_list(self) -> list:\n",
        "        \"\"\"\n",
        "        aggregates lists of products based on category into single list\n",
        "        \"\"\"\n",
        "        graphics_list = []\n",
        "        for group in self.parm_groups:\n",
        "            for element in group:\n",
        "                graphics_list.append(element[0])\n",
        "        return graphics_list\n",
        "\n",
        "    def download_this_file(self,url,destination) -> None:\n",
        "        try:\n",
        "            opener = urllib.request.build_opener()\n",
        "            opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
        "            urllib.request.install_opener(opener)\n",
        "            urllib.request.urlretrieve(url,destination)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    def download_and_store_images(self) -> None:\n",
        "        \"\"\"\n",
        "        download and store images\n",
        "        Returns nothing\n",
        "        \"\"\"\n",
        "        if not os.path.exists(BASEDIR):\n",
        "            os.mkdir(BASEDIR)\n",
        "        for date_hour in self.date_hour_list:\n",
        "\n",
        "            # create an image directory for each hour being downloaded\n",
        "            hour_dir = os.path.join(BASEDIR,date_hour)\n",
        "            try:\n",
        "                if not os.path.exists(hour_dir):\n",
        "                    os.mkdir(hour_dir)\n",
        "            except ValueError:\n",
        "                print(f'Can not make {hour_dir}')\n",
        "\n",
        "            # stage html viewer in each hour subdir\n",
        "            self.download_this_file(viewer_url,os.path.join(hour_dir,'viewer.html'))\n",
        "\n",
        "            for i,g in enumerate(self.graphics_list):\n",
        "                graphic = self.graphics_list[i]\n",
        "                #Example: https://www.spc.noaa.gov/exper/mesoanalysis/s16/pmsl/pmsl_22102521.gif\n",
        "                source_filename = f'{graphic}_{date_hour}.gif'\n",
        "                dest_filename = f'{graphic}.gif'\n",
        "                full_url = f'{self.url_pre}{self.sector_name}/{graphic}/{source_filename}'\n",
        "\n",
        "                # all downloaded files will be renamed to remove date and hour to standardize names\n",
        "                destination_filepath = os.path.join(hour_dir,dest_filename)\n",
        "                self.download_this_file(full_url,destination_filepath)\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------------------\n",
        "# Instantiate class\n",
        "# --------------------------------------------------------------------------------------\n",
        "if __name__ == '__main__':\n",
        "    GetMesoImages(start_datetime_str,hours_duration,sector,group_list,False)\n"
      ],
      "metadata": {
        "id": "MmWdsoUPA3_D",
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "#!pip install PIL\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Absolute path to this script\n",
        "scriptdir = '.'\n",
        "images = os.path.join(scriptdir, 'graphics')\n",
        "\n",
        "# Walk through directory\n",
        "for root, subfolders, files in os.walk(images):\n",
        "    for filename in files:\n",
        "        print(filename)\n",
        "        try:\n",
        "            image = Image.open(os.path.join(scriptdir, root, filename))\n",
        "            # If image has an alpha channel\n",
        "            print(image.mode)\n",
        "            if image.mode == 'P':\n",
        "                print(\"alpha!\")\n",
        "                # Create a blank background image\n",
        "                bg = Image.new('RGB', image.size, (255, 255, 255))\n",
        "                # Paste image to background image\n",
        "                bg.paste(image, (0, 0), image)\n",
        "                # Save pasted image as image\n",
        "                bg.save(os.path.join('/content/graphics', filename), \"PNG\")\n",
        "\n",
        "        except:\n",
        "            pass"
      ],
      "metadata": {
        "id": "NlvUVhSOs-pk",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}