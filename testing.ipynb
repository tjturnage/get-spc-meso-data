{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime,timedelta\n",
    "import urllib.request\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "surface = [\n",
    "['pmsl', 'Pressure and Wind'], ['bigsfc', 'Surface Plot'], ['ttd', 'Temp/Wind/Dwpt'],\n",
    "['thet', 'MSL Press/Theta-e/Wind'], ['mcon', 'Moisture Convergence'], ['thea', 'Theta-E Advection'],\n",
    "['mxth', 'Mixing Ratio / Theta'], ['icon', 'Inst Contraction Rate'], ['trap', 'Fluid Trapping'],\n",
    "['vtm', 'Velocity Tensor Mag'], ['dvvr', 'Sfc Div and Vort'],\n",
    "['def', 'Deformation / Axis of Dilitation'],['pchg', '2hr Press Change'],\n",
    "['temp_chg', '3hr Temp Change'], ['dwpt_chg', '3hr Dewpoint Change'], \n",
    "['mixr_chg', '3hr 100mb MixR Change'], ['thte_chg', '3hr Thetae Change']]\n",
    "\n",
    "upper_air =[['925mb', '925mb Analysis'], ['850mb2', '850mb Analysis'],\n",
    "['850mb', '850mb Analysis v2'], ['700mb', '700mb Analysis'], ['500mb', '500mb Analysis'],\n",
    "['300mb', '300mb Analysis'], ['dlcp', 'Deep Moist Conv'], ['tadv_925', '925mb Temp Adv'],\n",
    "['tadv', '850mb Temp Adv'], ['7tad', '700mb Temp Adv'], ['sfnt', 'Surface FGEN'],\n",
    "['9fnt', '925mb FGEN'], ['8fnt', '850mb FGEN'], ['7fnt', '700mb FGEN'], ['epvl', '850 fgen & EPV'],\n",
    "['epvm', '700 fgen & EPV'], ['98ft', '925-850mb FGEN'], ['857f', '850-700mb FGEN'],\n",
    "['75ft', '700-500mb FGEN'], ['vadv', '700-400mb Diff PVA'], ['padv', '400-250mb Pot Vort Adv'],\n",
    "['ddiv', '850-250mb Diff Div'], ['ageo', '300mb Jet Circ'], ['500mb_chg', '12hr H5 chg'],\n",
    "['trap_500', 'Fluid Trapping (H500)'], ['trap_250', 'Fluid Trapping (H250)']]\n",
    "\n",
    "thermodynamics = [['sbcp', 'SBCAPE'], ['mlcp', 'MLCAPE'], ['mucp', 'MUCAPE'],\n",
    "['eltm', 'EL Temp/MUCAPE/MUCIN'], ['ncap', 'CAPE - Normalized'], ['dcape', 'CAPE - Downdraft'],\n",
    "['muli', 'Sfc Based LI'], ['laps', 'Mid-Level Lapse Rates'], ['lllr', 'Low-Level Lapse Rates'], \n",
    "['maxlr', 'Max 2-6 km AGL Lapse Rate'], ['lclh', 'LCL hght'], ['lfch', 'LFC hght'],\n",
    "['lfrh', 'LCL-LFC RH'], ['sbcp_chg', '3-hour SBCAPE Change'], ['sbcn_chg', '3-hour SBCIN Change'],\n",
    "['mlcp_chg', '3-hour MLCAPE Change'], ['mucp_chg', '3-hour MUCAPE Change'],\n",
    "['lllr_chg', '3-hour Low LR Change'], ['laps_chg', '6-hour Mid LR Change'],\n",
    "['skewt', 'Skew-T Maps']]\n",
    "\n",
    "wind_shear = [['eshr', 'Bulk Shear - Effective'], ['shr6', 'Bulk Shear - Sfc-6km'],\n",
    "['shr8', 'Bulk Shear - Sfc-8km'], ['shr3', 'Bulk Shear - Sfc-3km'],\n",
    "['shr1', 'Bulk Shear - Sfc-1km'],['brns', 'BRN Shear'], ['effh', 'SR Helicity - Effective'],\n",
    "['srh3', 'SR Helicity - Sfc-3km'], ['srh1', 'SR Helicity - Sfc-1km'],\n",
    "['srh5', 'SR Helicity - Sfc-500m'], ['llsr', 'SR Wind - Sfc-2km'], ['mlsr', 'SR Wind - 4-6km'], \n",
    "['ulsr', 'SR Wind - 9-11km'], ['alsr', 'SR Wind - Anvil Level'], ['mnwd', '850-300mb Mean Wind'],\n",
    "['xover', '850 and 500mb Winds'], ['srh3_chg', '3hr Sfc-3km SR Helicity Change'],\n",
    "['shr1_chg', '3hr Sfc-1km Bulk Shear Change'], ['shr6_chg', '3hr Sfc-6km Bulk Shear Change'], \n",
    "['hodo', 'Hodograph Map']]\n",
    "\n",
    "composite_indices = [['scp', 'Supercell Composite'], ['stor', 'Sig Tor (fixed)'],\n",
    "['stpc', 'Sig Tor (eff)'], ['stpc5', 'Sig Tor (0-500m SRH)'], ['sigt1', 'Cond Prob SigTor 1'],\n",
    "['sigt2', 'Cond Prob SigTor 2'], ['nstp', 'Non-Supercell Tor'], ['vtp3', 'Violent Tor Parm'],\n",
    "['sigh', 'Significant Hail'], ['sars1', 'SARS Hail Size'], ['sars2', 'SARS Hail %age'],\n",
    "['lghl', 'Large Hail Parm'], ['dcp', 'Derecho Comp'], ['cbsig', 'Craven/Brooks SigSvr'],\n",
    "['brn', 'Bulk Ri Number'], ['mcsm', 'MCS Maint'], ['mbcp', 'Microburst Composite'],\n",
    "['desp', 'Enh Stretch Pot'], ['ehi1', 'EHI - Sfc-1km'], ['ehi3', 'EHI - Sfc-3km'],\n",
    "['vgp3', 'VGP - Sfc-3km'], ['crit', 'Critical Angle']]\n",
    "\n",
    "multi_parameter_fields = [['mlcp_eshr', 'MLCAPE / Eff Shear'],['cpsh', 'MUCAPE / Eff Shear'],\n",
    "['comp', 'MU LI / H8 & H5 Wind'], ['lcls', 'LCL Hgt / 0-1 SRH'],\n",
    "['lr3c', '0-3km Lapse Rate/MLCAPE'], ['3cape_shr3', '0-3km Bulk Shear/MLCAPE'],\n",
    "['3cvr', 'Sfc Vort / 0-3km MLCAPE'], ['tdlr', 'Sfc Dwpt / H7-H5 LapseR'],\n",
    "['qlcs1', '0-3km ThetaE diff/Shear Vec & MUCAPE'],\n",
    "['qlcs2', '', '0-3km ThetaE diff/Shear Vec & MLCAPE']]\n",
    "\n",
    "heavy_rain = [['pwtr', 'PWAT'], ['tran_925', '925 Moist Trans'], ['tran', '850 Moist Trans'],\n",
    "['tran_925-850', '925-850 Mtrans'],['prop', 'Propagation Vec'], ['peff', 'Pcpn Potential'],\n",
    "['mixr', '100mb Mean Mixing Ratio']]\n",
    "\n",
    "winter_weather = [['ptyp', 'Precipitation Type'], ['epvl', '800-750mb EPVg'],\n",
    "['epvm', '650-500mb EPVg'],['les1', 'Lake Effect Snow 1'],['les2', 'Lake Effect Snow 2'],\n",
    "['snsq', 'Snow Squall Parameter'],\n",
    "['dend', 'Dendritic Growth Layer Depth'], ['dendrh', 'Dendritic Growth Layer RH']]\n",
    "\n",
    "fire_weather = [ ['sfir', 'Sfc RH / T / Wind'], ['fosb', 'Fosberg Index'],\n",
    "['lhan', 'Low Haines Index'],['mhan', 'Mid Haines Index'],['hhan', 'High Haines Index'],\n",
    "['lasi', 'Lower Atmos Severity Index']]\n",
    "\n",
    "classic = [['ttot', 'Total Totals'], ['show', 'Showalter Index'], ['kidx', 'K Index']]\n",
    "\n",
    "beta = [['sherbe', 'SHERBE'], ['moshe', 'Modified SHERBE'], ['cwasp', 'CWASP'], \n",
    "['tehi', 'Tornadic 0-1 km EHI'], ['tts', 'Tornadic Tilting and Stretching parameter (TTS)'],\n",
    "['ptstpe', 'Conditional probability of EF0+ tornadoes'],\n",
    "['pstpe', 'Conditional probability of EF2+ tornadoes'], ['pvstpe', 'Conditional probability of EF4+ tornadoes']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#######################################################################################################################\n",
    "# Set directory in which image directories and images will be created\n",
    "#--------------------------------------------------------------------\n",
    "BASEDIR = \"C:/data/events\"\n",
    "#--------------------------------------------------------------------\n",
    "@dataclass\n",
    "class GetMesoImages:\n",
    "    \"\"\"\n",
    "    start_date_hour\n",
    "            string: Date and Hour to start grabbing images -- yyyymmdd_hh\n",
    "    total_hours\n",
    "            int: number of hours from startingDateHour to grab images\n",
    "    sector\n",
    "            2 digit string (not integer) representing SPC meso sector to download\n",
    "                11:NW       12:SW           13:N Plns\n",
    "                14:C Plns   15:S Plns       16:NE\n",
    "                17:EC       18:SE           19:National\n",
    "                20:MW       21:Great Lakes\n",
    "    parm_groups\n",
    "            list of lists of strings. options are:\n",
    "                [surface, upper_air, thermodynamics, wind_shear, composite_indices,\n",
    "                multi_parameter_fields, heavy_rain, winter_weather, fire_weather, classic, beta]\n",
    "    location_bool\n",
    "            True: if obtaining images from a case requested of SPC\n",
    "                    -https://www.spc.noaa.gov/exper/mesoanalysis/archive/\n",
    "            False: if searching to see if images for a date already exist in their main directory\n",
    "                    -https://www.spc.noaa.gov/exper/mesoanalysis/\n",
    "    \"\"\"\n",
    "    start_date_hour: str\n",
    "    total_hours: int\n",
    "    sector: str\n",
    "    parm_groups: list\n",
    "    location_bool: bool\n",
    "    #date_hour_list: list\n",
    "    #graphics_list: list\n",
    "\n",
    "    def sector_name(self) -> str:\n",
    "        \"\"\"\n",
    "        adds an \"s\" to sectorname\n",
    "        \"\"\"\n",
    "        return f's{self.sector}'\n",
    "\n",
    "    def date_hour_list(self) -> list:\n",
    "        \"\"\"\n",
    "        use datetime to create list of strings representing date and hour\n",
    "        \"\"\"\n",
    "        date_hour_list = []\n",
    "        starting_datehour = datetime.strptime(self.start_date_hour,\"%Y%m%d_%H\")\n",
    "        ending_datehour = starting_datehour + timedelta(hours=self.total_hours)\n",
    "        while starting_datehour <= ending_datehour:\n",
    "            dt_str = datetime.strftime(starting_datehour,'%y%m%d%H')\n",
    "            date_hour_list.append(dt_str)\n",
    "            starting_datehour = starting_datehour + timedelta(hours=1)\n",
    "        print(self.date_hour_list)\n",
    "        return self.date_hour_list\n",
    "\n",
    "    def url_pre(self) -> str:\n",
    "        \"\"\"\n",
    "        set the url based on selection\n",
    "        \"\"\"\n",
    "        if self.location_bool:\n",
    "            return 'https://www.spc.noaa.gov/exper/mesoanalysis/archive/'\n",
    "        return 'https://www.spc.noaa.gov/exper/mesoanalysis/'\n",
    "\n",
    "    def full_elements_list(self) -> list:\n",
    "        \"\"\"\n",
    "        aggregates lists of products based on category into single list\n",
    "        \"\"\"\n",
    "        graphics_list = []\n",
    "        for group in self.parm_groups:\n",
    "            for element in group:\n",
    "                graphics_list.append(element[0])\n",
    "        return graphics_list\n",
    "\n",
    "    def download_and_store_images(self):\n",
    "        \"\"\"\n",
    "        download and store images\n",
    "        Returns nothing\n",
    "        \"\"\"\n",
    "        for date_hour in self.date_hour_list:\n",
    "            # create an image directory for each hour being downloaded\n",
    "            image_dir = os.path.join(BASEDIR,date_hour)\n",
    "            # copy meso graphics html browser into this new directory\n",
    "            src = os.path.join(os.getcwd(),'spc_meso_graphics_viewer.html')\n",
    "            try:\n",
    "                if not os.path.exists(image_dir):\n",
    "                    os.mkdir(image_dir)\n",
    "            except ValueError:\n",
    "                print(f'Can not make {image_dir}')\n",
    "            try:\n",
    "                shutil.copy2(src,image_dir)\n",
    "            except ValueError:\n",
    "                print('Can not copy html file')\n",
    "            for graphic in self.full_elements_list:\n",
    "                #Example: https://www.spc.noaa.gov/exper/mesoanalysis/s16/pmsl/pmsl_22102521.gif\n",
    "                source_filename = f'{graphic}_{date_hour}.gif'\n",
    "                dest_filename = f'{graphic}.gif'\n",
    "                full_url = f'{self.url_pre}{self.sector_name}/{graphic}/{source_filename}'\n",
    "                #print(fullURL)\n",
    "                # all downloaded files will be renamed to remove date and hour to standardize names\n",
    "                destination_filepath = os.path.join(image_dir,dest_filename)\n",
    "                #print(destination_filepath)\n",
    "                try:\n",
    "                    opener = urllib.request.build_opener()\n",
    "                    opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "                    urllib.request.install_opener(opener)\n",
    "                    urllib.request.urlretrieve(full_url,destination_filepath)\n",
    "                except ValueError:\n",
    "                    print(f'could not download {source_filename}')\n",
    "\n",
    "\n",
    "        def main() -> None:\n",
    "            \"\"\"Echo the input arguments to standard output\"\"\"\n",
    "            self.GetMesoImages('20221223_16',4,'21',groups,True)\n",
    "            self.date_hour_list = self.date_hour_list()\n",
    "            print(self.date_hour_list)\n",
    "            self.download_and_store_images()\n",
    "\n",
    "\n",
    "\n",
    "        if __name__ == '__main__':\n",
    "            main()\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# Instantiate class\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "#groups = [surface, upper_air, thermodynamics, wind_shear, composite_indices, multi_parameter_fields, heavy_rain, winter_weather, fire_weather, classic, beta]\n",
    "groups = [surface, upper_air, thermodynamics, wind_shear, composite_indices, multi_parameter_fields,\n",
    "heavy_rain, winter_weather]\n",
    "\n",
    "#test = GetMesoImages('20221223_16',4,'21',groups,True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mydashenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74bdc28edc52f6095eb7a4bcd585bfd32169b2465ff3caa4592f95870b5ba073"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
